---
title: Multilevel Modelling, Pairwise Comparisons and Effect Statistics for Sports
  Scientist
author: Ryan Curtis, PhD
date: '2020-08-14'
slug: multilevel-modelling-pairwise-comparisons-and-effect-statistics-for-sports-scientist
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-08-14T16:28:18-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/clipboard/clipboard.min.js"></script>
<link href="/rmarkdown-libs/primer-tooltips/build.css" rel="stylesheet" />
<link href="/rmarkdown-libs/klippy/css/klippy.min.css" rel="stylesheet" />
<script src="/rmarkdown-libs/klippy/js/klippy.min.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>


<div id="why-sports-scientist-should-be-familiar-with-mixed-effects-multi-level-modelling-and-effect-statistics" class="section level1">
<h1>Why sports scientist should be familiar with mixed effects (multi-level) modelling and effect statistics…</h1>
<p>Skill in analyzing longitudinal data is particularly important for assessing phenomena that fluctuate over time. There are several important considerations when conducting longitudinal analysis including; accounting for the dependencies created by repeated measures, dealing with missing or unbalanced data (common occurrence in athlete monitoring practices), differentiating between-athlete from within-athlete effects, accounting for time-varying (e.g., workload, perceived fatigue) and time-invariant factors (e.g., sex, role, position) and establishing the influence of time.</p>
<p>Multi-level models are quite useful in assessing longitudinal outcomes because of their ability to incorporate multiple factors into the model, include time-variant and time-invariant factors, account for between and within-athlete variability, handle missing and unbalanced data and account for repeated measures over time <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6169745/">(Windt et al. 2018)</a>.</p>
<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
</div>
<div id="load-data" class="section level1">
<h1>Load Data</h1>
</div>
<div id="identify-structure-and-view-dataframe" class="section level1">
<h1>Identify structure and view dataframe</h1>
<p>It’s always good to take a look at the structure of the data. Main thing is we want to make sure the data is in long format and each column is formatted appropriately (numeric, date, factor, etc.).</p>
<pre class="r"><code>#structure of dataframe
str(data)</code></pre>
<pre><code>## &#39;data.frame&#39;:    2145 obs. of  3 variables:
##  $ Athlete : chr  &quot;Athlete1&quot; &quot;Athlete1&quot; &quot;Athlete1&quot; &quot;Athlete1&quot; ...
##  $ Season  : Factor w/ 3 levels &quot;Preseason&quot;,&quot;Inseason&quot;,..: 1 1 1 1 1 1 2 2 2 2 ...
##  $ Distance: num  5431 5142 4530 6289 7132 ...</code></pre>
<pre class="r"><code>#view dataframe
head(data)</code></pre>
<pre><code>##    Athlete    Season Distance
## 1 Athlete1 Preseason     5431
## 2 Athlete1 Preseason     5142
## 3 Athlete1 Preseason     4530
## 4 Athlete1 Preseason     6289
## 5 Athlete1 Preseason     7132
## 6 Athlete1 Preseason     3089</code></pre>
</div>
<div id="fit-mixed-effects-model-with-lme4" class="section level1">
<h1>Fit Mixed Effects Model with lme4</h1>
<p>With this model, we are doing a simple LMM, with Distance covered as our dependent variable, Season (preseason, inseason and postseason) as our independent variable (fixed effect) and we are clustering the data by athlete (random effect). Although one of the benefits of LMM is its abililtiy to incorporate multiple factors into a model (therefore controlling for various contextual factors), for demonstration purposes we’ll keep the model as a simple univariate example.</p>
<pre class="r"><code>library(lmerTest)

#fit model
fit &lt;- lmer(Distance ~ Season + (1|Athlete), data = data)

#view results
summary(fit)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: Distance ~ Season + (1 | Athlete)
##    Data: data
## 
## REML criterion at convergence: 38315.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.9472 -0.6535  0.0134  0.6598  3.5812 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Athlete  (Intercept)  562888   750.3  
##  Residual             3227796  1796.6  
## Number of obs: 2145, groups:  Athlete, 59
## 
## Fixed effects:
##                  Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)        4822.9      142.3  182.5  33.892  &lt; 2e-16 ***
## SeasonInseason     -509.0      117.0 2133.5  -4.352 1.41e-05 ***
## SeasonPostseason   -647.2      133.0 2102.7  -4.866 1.22e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) SsnIns
## SeasonInssn -0.658       
## SeasnPstssn -0.549  0.671</code></pre>
</div>
<div id="a-more-detailed-summary" class="section level1">
<h1>A More Detailed Summary…</h1>
<p>I prefer to use the tab_model function in the sjPlot package by Daniel Lüdecke. You get a nice html table output that is publication worthy. There are several options to customize the table output, you can find that tutorial <a href="https://strengejacke.github.io/sjPlot/articles/tab_model_estimates.html">here</a>. In addition to the standard components you get with a traditional summary() output, tab_model() provides a few other components we need to interpet the model such as the ICC value and marginal/conditoinal R<sup>2</sup> values.</p>
<p>The higher the ICC value the more justified the use of LMM vs. a more traditional statistic (ANOVA in this instance). ICC’s can be interpeted as the proportion of variance explained by clustering. An ICC &gt; 0.1 is generally accepted as the minimal threshold for justifying the use of LMM, so in other words, at least 10% of the variance in Distance should be explained by clustering the observations by player.</p>
<pre class="r"><code># detailed summary
library(sjPlot)
tab_model(fit)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
Distance
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4822.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4543.99 – 5101.80
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Season [Inseason]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-508.98
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-738.22 – -279.74
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Season [Postseason]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-647.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-907.84 – -386.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td colspan="4" style="font-weight:bold; text-align:left; padding-top:.8em;">
Random Effects
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
σ<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
3227795.80
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
τ<sub>00</sub> <sub>Athlete</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
562887.86
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
ICC
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.15
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N <sub>Athlete</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
59
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
2145
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.011 / 0.158
</td>
</tr>
</table>
<p>In this instance, the ICC is 0.15 so the use of LMM is appropriate.</p>
<p>The other outputs of interest are our Marginal and Conditoinal R<sup>2</sup> values (calculated based on <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210x.2012.00261.x">Nakagawa et al.</a>). These show the proportion of variance explained by the fixed effect only (Marginal R<sup>2</sup>) and fixed + random effect (Conditional R<sup>2</sup>), respectively.</p>
<p>So for this model, we would could conclude that season phase is explaining very little (~1%) about the distance covered in each session. It’s important to have this context becuase although there are significant differences in distance covered between the season phases, season phase by itself is not a meaninful determinant of session distance. On the other hand, the conditional R<sup>2</sup> is ~0.16, so we can see that the proportion of variance explained by the combination of season and accounting for individual variance is much higher. The marginal R<sup>2</sup> is 0.01 (fixed effect) and the ICC is 0.15 (random effect), so a conditional R<sup>2</sup> of 0.16 makes sense.</p>
</div>
<div id="visualize-data" class="section level1">
<h1>Visualize Data</h1>
<p>If you want to visualize the model (or any other mixed effects model [generalized, ordinal, etc.]), I would recommend using the ggeffects package (also by Daniel Lüdecke) combined with ggplot2 functions. You can find the ggeffects tutorial <a href="https://strengejacke.github.io/ggeffects/">here</a>. You can use the <strong>fit</strong> object with <strong>ggpredict()</strong> to create a data frame for plotting, pass a <strong>plot</strong> function, and then add <strong>ggplot2</strong> functions as needed to clean up the visualization. Here is a sample output from ggpredict().</p>
<pre class="r"><code>library(ggeffects)
library(ggplot2)

#create plot dataframe
plot_data &lt;- ggpredict(fit, terms = c(&quot;Season&quot;))
plot_data</code></pre>
<pre><code>## 
## # Predicted values of Distance
## # x = Season
## 
## x          | Predicted |     SE |             95% CI
## ----------------------------------------------------
## Preseason  |   4822.89 | 142.30 | [4543.99, 5101.80]
## Inseason   |   4313.91 | 109.66 | [4098.98, 4528.85]
## Postseason |   4175.73 | 130.98 | [3919.01, 4432.46]
## 
## Adjusted for:
## * Athlete = 0 (population-level)</code></pre>
<p>Here is the plot output…</p>
<pre class="r"><code>#create plot
plot_data %&gt;%
  #reorder independent variable
  mutate(x = ordered(x, levels = c(&quot;Preseason&quot;, &quot;Inseason&quot;, &quot;Postseason&quot;))) %&gt;%
  #use plot function with ggpredict objects
  plot() + 
  #add ggplot2 as needed
  theme_blank() + ylim(c(3000,5500)) + ggtitle(&quot;Session Distance by Season Phase&quot;)</code></pre>
<p><img src="/post/2020-08-14-multilevel-modelling-pairwise-comparisons-and-effect-statistics-for-sports-scientist.en_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="fit-tukey-for-pairwise-comparisons" class="section level1">
<h1>Fit Tukey for Pairwise Comparisons</h1>
<p>Since the model summary indicates we have some significant differences in session distance by season phase, the next step is to compare the levels against each other to see where the differences lie. We can tell by the model summary() output that Inseason and Postseason are significantly different than Preseason (model intercept), but we want to run this model through a post hoc test to confirm where the differences are.</p>
<p>As expected based on the model summary, both inseason and postseason session loads are less than the preseason. This makes sense. Preseason is used as a prepatory period and is accompanied by increased player loading.</p>
<pre class="r"><code>library(multcomp)

# pairwise comparisons
fit_tukey &lt;- glht(fit, linfct=mcp(Season=&quot;Tukey&quot;))
summary(fit_tukey)</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lmer(formula = Distance ~ Season + (1 | Athlete), data = data)
## 
## Linear Hypotheses:
##                             Estimate Std. Error z value Pr(&gt;|z|)    
## Inseason - Preseason == 0     -509.0      117.0  -4.352   &lt;1e-04 ***
## Postseason - Preseason == 0   -647.2      133.0  -4.866   &lt;1e-04 ***
## Postseason - Inseason == 0    -138.2      102.4  -1.349    0.364    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>Another important thing to note here, the difference estimates from this Tukey are the same as the lmer model summary, so we can also use these as our mean differences for the effect size calculations.</p>
</div>
<div id="calculating-effect-sizes" class="section level1">
<h1>Calculating Effect Sizes</h1>
<p>There isn’t a consensus on the best or preferred method of calculating effect sizes from within-subject designs. I’m also not aware of any packages that compute standardized effect sizes directly from a lmer object. Jake Westfall goes into great detail <a href="http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/">here</a> on the subject, detailing several of the ways cohens d and d-like effect sizes can be estimated. The important thing to note here is transparency when reporting a standardized effect size.</p>
<div id="option-1-classical-cohens-d-calculation" class="section level2">
<h2>Option 1: Classical Cohen’s D Calculation</h2>
<p>First, we can separate out the players distances by season.</p>
<pre class="r"><code>preseason_data &lt;- data %&gt;% filter(Season == &quot;Preseason&quot;) %&gt;% dplyr::select(Distance)
inseason_data &lt;- data %&gt;% filter(Season == &quot;Inseason&quot;) %&gt;% dplyr::select(Distance)
postseason_data &lt;- data %&gt;% filter(Season == &quot;Postseason&quot;) %&gt;% dplyr::select(Distance)</code></pre>
<p>You can create a cohen’s d function yourself. Credit to <a href="https://stackoverflow.com/questions/15436702/estimate-cohens-d-for-effect-size">this</a> post on StackOverflow. I’m not using the absolute value of the mean difference - as in the original cohen equation - so we can see the direction of the effect.</p>
<pre class="r"><code>cohens_d &lt;- function(x, y) {
  lx &lt;- length(x)- 1                  # Sample Size X
  ly &lt;- length(y)- 1                  # Sample Size Y
  md  &lt;- mean(x) - mean(y)       # Mean Difference
  csd &lt;- lx * var(x) + ly * var(y)
  csd &lt;- csd/(lx + ly)
  csd &lt;- sqrt(csd)                    # Pooled SD
  
  md/csd                       # Cohen&#39;s d
}


cohens_d(inseason_data$Distance, preseason_data$Distance)</code></pre>
<pre><code>## [1] -0.5073199</code></pre>
<p>…or there are R packages for computing classical cohen’s d such as <a href="https://cran.r-project.org/web/packages/lsr/lsr.pdf">lsr</a> and <a href="https://cran.r-project.org/web/packages/effsize/effsize.pdf">effsize</a>…please note that these functions take the absolute value of the mean difference so all results will be positive.</p>
<pre class="r"><code>#install.packages(&quot;lsr&quot;)
#install.packages(&quot;effsize&quot;)
library(lsr)
lsr::cohensD(preseason_data$Distance, inseason_data$Distance)</code></pre>
<pre><code>## [1] 0.5073199</code></pre>
<p>The <strong>effsize</strong> package which also give you 95%CI.</p>
<pre class="r"><code>library(effsize)</code></pre>
<pre><code>## Warning: package &#39;effsize&#39; was built under R version 3.6.3</code></pre>
<pre class="r"><code>effsize::cohen.d(preseason_data$Distance, inseason_data$Distance)</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.5073199 (medium)
## 95 percent confidence interval:
##     lower     upper 
## 0.3846418 0.6299981</code></pre>
</div>
<div id="option-2-standardized-effect-size-using-residual-standard-deviation" class="section level2">
<h2>Option 2: Standardized Effect Size using Residual Standard Deviation</h2>
<div id="extract-mean-differences" class="section level3">
<h3>Extract Mean Differences</h3>
<p>For the numerator we need mean differences, which we can grab from the Tukey summary (or you could gather them from the lmer model summary, results are the same…your choice).</p>
<pre class="r"><code>#make tukey summary into an object
res &lt;- summary(fit_tukey)

#extract first tukey comparison and make into an object
res$test[-(1:2)]$coefficients[1]</code></pre>
<pre><code>## Inseason - Preseason 
##            -508.9801</code></pre>
<pre class="r"><code>meandiff_1 &lt;- res$test[-(1:2)]$coefficients[1]


#extract second tukey comparison and make into an object
res$test[-(1:2)]$coefficients[2]</code></pre>
<pre><code>## Postseason - Preseason 
##              -647.1606</code></pre>
<pre class="r"><code>meandiff_2 &lt;- res$test[-(1:2)]$coefficients[2]


#extract third tukey comparison and make into an object
res$test[-(1:2)]$coefficients[3]</code></pre>
<pre><code>## Postseason - Inseason 
##             -138.1805</code></pre>
<pre class="r"><code>meandiff_3 &lt;- res$test[-(1:2)]$coefficients[3]</code></pre>
<p>We’ve already extracted mean differences for each comparison, so we only need to gather the residual standard deviation for this one. There are a few ways to do this, but the easiest is…</p>
<pre class="r"><code>#extract the sd directly
summary(fit)$sigma</code></pre>
<pre><code>## [1] 1796.607</code></pre>
<pre class="r"><code>#create pooled residual sd object
pooled_sd_residual &lt;- summary(fit)$sigma</code></pre>
<pre class="r"><code>#calculate effect sizes
meandiff_1/pooled_sd_residual</code></pre>
<pre><code>## Inseason - Preseason 
##           -0.2833008</code></pre>
<pre class="r"><code>meandiff_2/pooled_sd_residual</code></pre>
<pre><code>## Postseason - Preseason 
##             -0.3602127</code></pre>
<pre class="r"><code>meandiff_3/pooled_sd_residual</code></pre>
<pre><code>## Postseason - Inseason 
##           -0.07691193</code></pre>
</div>
</div>
<div id="option-3-standardized-effect-size-using-all-variance-components" class="section level2">
<h2>Option 3: Standardized Effect Size using All Variance Components</h2>
<p>We need all random effect variance components, which in this model are just the residual and within-athlete variances. You’ve already seen these variances in the model summary, so these calculations can be done simply by hand, but since we’re using R lets extract them using the <strong>VarCorr</strong> function and take the square root of the sum.</p>
<pre class="r"><code>#make VarCorr object from the model fit
vc &lt;- VarCorr(fit)

#square root of the sum of model variance components (pooled standard deviation)
sqrt(as.data.frame(vc)$vcov[1] + as.data.frame(vc)$vcov[2])</code></pre>
<pre><code>## [1] 1946.968</code></pre>
<pre class="r"><code>#make pooled sd object
pooled_sd_allvar &lt;- sqrt(as.data.frame(vc)$vcov[1] + as.data.frame(vc)$vcov[2])</code></pre>
<pre class="r"><code>#calculate effect sizes
meandiff_1/pooled_sd_allvar</code></pre>
<pre><code>## Inseason - Preseason 
##            -0.261422</code></pre>
<pre class="r"><code>meandiff_2/pooled_sd_allvar</code></pre>
<pre><code>## Postseason - Preseason 
##             -0.3323941</code></pre>
<pre class="r"><code>meandiff_3/pooled_sd_allvar</code></pre>
<pre><code>## Postseason - Inseason 
##           -0.07097215</code></pre>
<div id="combine-effect-sizes-into-a-table" class="section level3">
<h3>Combine Effect Sizes into a Table</h3>
<p>Lastly, we can put the different effect size calculations into a table so we can more easily compare.</p>
<pre class="r"><code>#gather cohen effect sizes
inseason_preseason_cohen &lt;- cohens_d(inseason_data$Distance, preseason_data$Distance)
postseason_preseason_cohen &lt;- cohens_d(postseason_data$Distance, preseason_data$Distance)
postseason_inseason_cohen &lt;- cohens_d(postseason_data$Distance, inseason_data$Distance)


#make dataframe
effect_data_cohen &lt;- data.frame(
  &quot;Season&quot; = c(&quot;Inseason - Preseason&quot;, &quot;Postseason - Preseason&quot;, &quot;Postseason - Inseason&quot;),
  &quot;Effect Size Cohen&quot; = c(inseason_preseason_cohen, postseason_preseason_cohen, postseason_inseason_cohen))</code></pre>
<pre class="r"><code>#make results into dataframes for more effect data binding
comparison_1_effect_residual &lt;- as.data.frame(meandiff_1/pooled_sd_residual)
comparison_2_effect_residual &lt;- as.data.frame(meandiff_2/pooled_sd_residual)
comparison_3_effect_residual &lt;- as.data.frame(meandiff_3/pooled_sd_residual)

comparison_1_effect_allvar &lt;- as.data.frame(meandiff_1/pooled_sd_allvar)
comparison_2_effect_allvar &lt;- as.data.frame(meandiff_2/pooled_sd_allvar)
comparison_3_effect_allvar &lt;- as.data.frame(meandiff_3/pooled_sd_allvar)


#rename first column of data frame
names(comparison_1_effect_residual)[1] &lt;- &quot;Effect Size (Residuals)&quot;
names(comparison_2_effect_residual)[1] &lt;- &quot;Effect Size (Residuals)&quot;
names(comparison_3_effect_residual)[1] &lt;- &quot;Effect Size (Residuals)&quot;

names(comparison_1_effect_allvar)[1] &lt;- &quot;Effect Size (All Variance)&quot;
names(comparison_2_effect_allvar)[1] &lt;- &quot;Effect Size (All Variance)&quot;
names(comparison_3_effect_allvar)[1] &lt;- &quot;Effect Size (All Variance)&quot;


#bind data rows and join by Season
effect_data &lt;- effect_data_cohen %&gt;%
  left_join(bind_rows(comparison_1_effect_residual, comparison_2_effect_residual, comparison_3_effect_residual) %&gt;% 
  #round effect size values to 2 decimal places
  round(2) %&gt;%
  #convert rownames to a column
  rownames_to_column(var = &quot;Season&quot;), by = &quot;Season&quot;) %&gt;%
  left_join(bind_rows(comparison_1_effect_allvar, comparison_2_effect_allvar, comparison_3_effect_allvar) %&gt;% 
  round(2) %&gt;%
  rownames_to_column(var = &quot;Season&quot;), by = &quot;Season&quot;) %&gt;%
  rename(`Effect Size (Cohen)` = Effect.Size.Cohen) %&gt;%
  mutate(`Effect Size (Cohen)` = round(`Effect Size (Cohen)`, 2))</code></pre>
</div>
<div id="view-effect-size-results" class="section level3">
<h3>View Effect Size Results</h3>
<pre class="r"><code>#view effect size dataframe
library(DT)
DT::datatable(effect_data, rownames = FALSE, options = list(dom= &quot;t&quot;))</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["Inseason - Preseason","Postseason - Preseason","Postseason - Inseason"],[-0.51,-0.37,0.1],[-0.28,-0.36,-0.08],[-0.26,-0.33,-0.07]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Season<\/th>\n      <th>Effect Size (Cohen)<\/th>\n      <th>Effect Size (Residuals)<\/th>\n      <th>Effect Size (All Variance)<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="add-effect-size-interpretations" class="section level3">
<h3>Add Effect Size Interpretations</h3>
<p>There have a been different propositions regarding the qualitative interpretation of ES’s. The original interpretation given by Cohen suggests &lt;0.5 is a small effect, 0.5 to 0.7 is a moderate effect, and &gt;0.8 is interpreted as a large effect. More recently Hopkins suggested a revised scale with threshold values at 0.2 (small), 0.6 (moderate), 1.2 (large), 2.0 (very large) and &gt;4 (nearly perfect).</p>
<pre class="r"><code>effect_interpretation &lt;- effect_data %&gt;%
  dplyr::select(Season, `Effect Size (Cohen)`) %&gt;%
   #interpret effect size
  mutate(`Hopkins Interpretation` = ifelse(abs(`Effect Size (Cohen)`) &lt;= 0.2, &quot;Trivial&quot;, ifelse(abs(`Effect Size (Cohen)`) &lt;= 0.6, &quot;Small&quot;, ifelse(abs(`Effect Size (Cohen)`) &lt;= 1.2, &quot;Moderate&quot;, ifelse(abs(`Effect Size (Cohen)`) &lt;= 2, &quot;Large&quot;, ifelse(abs(`Effect Size (Cohen)`) &lt;= 4, &quot;Very Large&quot;, &quot;Nearly Perfect&quot;)))))) %&gt;%
  mutate(`Cohen&#39;s Interpretation` = ifelse(abs(`Effect Size (Cohen)`) &lt;= 0.2, &quot;Small&quot;, ifelse(abs(`Effect Size (Cohen)`) &lt;= 0.5, &quot;Medium&quot;, &quot;Large&quot;)))


DT::datatable(effect_interpretation, rownames = FALSE, options = list(dom= &quot;t&quot;))</code></pre>
<div id="htmlwidget-2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","data":[["Inseason - Preseason","Postseason - Preseason","Postseason - Inseason"],[-0.51,-0.37,0.1],["Small","Small","Trivial"],["Large","Medium","Small"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Season<\/th>\n      <th>Effect Size (Cohen)<\/th>\n      <th>Hopkins Interpretation<\/th>\n      <th>Cohen's Interpretation<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","columnDefs":[{"className":"dt-right","targets":1}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>As noted earlier and worth mentioning again, there are a number of ways to calculate standardized effect sizes and there really is not one “right” way. The important thing is to detail which method you are using and make sure to label it appropriately. For instance, using residual SD and the square root of the sum of variance components from a mixed model for standardization are not traditional Cohen’s d statistics, so they should be referred to as standardized effect sizes.</p>
</div>
</div>
</div>
